{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c30d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92183aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb52ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3115 files belonging to 36 classes.\n",
      "All model classes: ['apple', 'banana', 'beetroot', 'bell pepper', 'cabbage', 'capsicum', 'carrot', 'cauliflower', 'chilli pepper', 'corn', 'cucumber', 'eggplant', 'garlic', 'ginger', 'grapes', 'jalepeno', 'kiwi', 'lemon', 'lettuce', 'mango', 'onion', 'orange', 'paprika', 'pear', 'peas', 'pineapple', 'pomegranate', 'potato', 'raddish', 'soy beans', 'spinach', 'sweetcorn', 'sweetpotato', 'tomato', 'turnip', 'watermelon']\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"./train\",\n",
    "    image_size=(128, 128),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "print(\"All model classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8208c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays created for checking whether it's a fruit or veggie later on\n",
    "fruits = [\"apple\", \"banana\", \"grapes\", \"kiwi\", \"lemon\", \"mango\", \"orange\", \"pear\", \"pineapple\", \"pomegranate\", \"watermelon\"]\n",
    "vegetables = [\"beetroot\", \"bell pepper\", \"cabbage\", \"capsicum\", \"carrot\", \"cauliflower\", \"chilli pepper\", \"corn\", \n",
    "              \"cucumber\", \"eggplant\", \"garlic\", \"ginger\", \"jalepeno\", \"lettuce\", \"onion\", \"paprika\", \"peas\", \n",
    "              \"potato\", \"raddish\", \"soy beans\", \"spinach\", \"sweetcorn\", \"sweetpotato\", \"tomato\", \"turnip\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cc3ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               4194432   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 36)                4644      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,292,324\n",
      "Trainable params: 4,292,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "# Create data augmentation layer\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "])\n",
    "\n",
    "# Optimize data pipeline with caching and prefetching\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Create validation split\n",
    "val_size = int(0.2 * 3115)  # 20% for validation\n",
    "train_size = 3115 - val_size\n",
    "\n",
    "train_ds = train_dataset.take(train_size)\n",
    "val_ds = train_dataset.skip(train_size)\n",
    "\n",
    "# Create the model with improvements\n",
    "model = models.Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(128, 128, 3)),\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(len(class_names), activation='softmax')  # One neuron per class\n",
    "])\n",
    "\n",
    "# Model summary to check architecture\n",
    "model.summary()\n",
    "\n",
    "# Define callbacks WITHOUT TensorBoard\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"fruit_veg_model_checkpoint\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_accuracy\"\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model with validation data and callbacks\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36350a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 359 files belonging to 36 classes.\n",
      "12/12 [==============================] - 3s 85ms/step - loss: 1.3420 - accuracy: 0.6017\n",
      "Test accuracy: 0.60\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test dataset if available\n",
    "try:\n",
    "    test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        './test',\n",
    "        image_size=(128, 128),\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    # Apply same preprocessing as training data\n",
    "    test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "    print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "except:\n",
    "    print(\"No test directory found or error loading test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e30b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict on new images\n",
    "def predict_image(loaded_model, img_path):\n",
    "    try:\n",
    "        img = load_img(img_path, target_size=(128, 128))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "        predictions = loaded_model.predict(img_array)\n",
    "        predicted_index = np.argmax(predictions[0])\n",
    "        predicted_class = class_names[predicted_index]\n",
    "        confidence = float(predictions[0][predicted_index])\n",
    "\n",
    "        print(f\"Model prediction: {predicted_class} (Confidence: {confidence:.2f})\")\n",
    "        \n",
    "        # Check if the predicted class is a fruit or vegetable\n",
    "        if predicted_class.lower() in fruits:\n",
    "            return \"Fruit\", predicted_class, confidence\n",
    "        elif predicted_class.lower() in vegetables:\n",
    "            return \"Vegetable\", predicted_class, confidence\n",
    "        else:\n",
    "            return \"Unknown category\", predicted_class, confidence\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b41d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Model prediction: pomegranate (Confidence: 0.62)\n",
      "Category: Fruit, Name: pomegranate, Confidence: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Making sure the folder exists\n",
    "save_path = r\"C:\\Users\\abios\\Desktop\\frootVeggieClassifier.h5\" # Note: pip install h5py\n",
    "# Save the trained model\n",
    "model.save(save_path)\n",
    "print(\"Model saved successfully\")\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    category, name, conf = predict_image(model, \"./input/app.jpeg\")\n",
    "    print(f\"Category: {category}, Name: {name}, Confidence: {conf:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with example prediction: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a587cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model_path = r\"C:\\Users\\abios\\Desktop\\frootVeggieClassifier.h5\"\n",
    "model = load_model(model_path)\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    category, name, conf = predict_image(model, \"./input/let.jpg\")\n",
    "    print(f\"Category: {category}, Name: {name}, Confidence: {conf:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with example prediction: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myAI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
